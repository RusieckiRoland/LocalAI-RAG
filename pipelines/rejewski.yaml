YAMLpipeline:
  name: marian_rejewski_code_analysis_nopCommerce_develop

  # Inheritance (optional):
  # - If present, loader merges parent -> child.
  # - settings: deep-merge (child overrides keys)
  # - steps: merged by `id`:
  #     * new id => appended
  #     * same id => overrides the whole step (simple rule)
  # - entry step is defined in settings.entry_step_id (deterministic start)
  extends: marian_rejewski_code_analysis_base

  settings:
    # Which step is the deterministic entry point
    entry_step_id: maybe_translate_in

    model_language: en

    # Active repository + index selection (server can host multiple)
    repository: "nopCommerce"
    active_index: "2025-12-14_develop"

    # Loop guard (prevents infinite "follow-up" loops)
    max_turn_loops: 4

    # Overall token budget for the retrieval context injected into the ANSWER call
    # (retrieval hits + graph neighborhood + targeted node texts)
    max_context_tokens: 5000

    # Token budget for conversation history injected into router/answer prompts.
    # If history grows beyond this, it is summarized once and then reused.
    max_history_tokens: 800

    # When new turns arrive and we already have a summary, we re-summarize:
    # summarize( previous_summary + new_turns ) to keep within max_history_tokens.
    history_summarization_policy: "incremental_resummarize"

    # Graph expansion defaults (bounded traversal to avoid explosion)
    graph_max_depth: 2
    graph_max_nodes: 120
    graph_edge_allowlist:
      - "ReadsFrom"
      - "WritesTo"
      - "Calls"
      - "Executes"
      - "FK"
      - "On"
      - "SynonymFor"
      - "ReferencedBy(C#)"

    # How many node bodies/snippets we are allowed to fetch by identity after graph expansion
    node_text_fetch_top_n: 12

    # Retrieval modes supported by the system:
    # - semantic: FAISS only
    # - bm25: keyword only (TF/BM25 index)
    # - hybrid: semantic + bm25 fused by RRF (planned)
    # - semantic_rerank: FAISS widen + keyword rerank (your current implementation)
    retrieval_modes:
      - semantic
      - bm25
      - hybrid
      - semantic_rerank

  steps:
    # 1) Normalize user input language.
    - id: maybe_translate_in
      action: translate_in_if_needed
      next: load_history

    # 2) Load conversation history for this user/session.
    - id: load_history
      action: load_conversation_history
      next: check_history_budget

    # 3) Ensure history fits into max_history_tokens.
    - id: check_history_budget
      action: check_context_budget
      input: history_for_prompt
      max_tokens_from_settings: "max_history_tokens"
      on_over_limit: call_model_summarize_history
      on_ok: call_model_router

    # 4) Summarize history with respect to current question.
    #    Persist summary; if we already have a summary, re-summarize summary + new turns.
    - id: call_model_summarize_history
      action: call_model
      prompt_key: "rejewski_history_summarizer_v1"
      next: call_model_router

    # 5) Router / Planner step.
    #    Output must be ONE line with exactly one prefix:
    #      [SEMANTIC:] <better query>
    #      [BM25:] <keywords/query>
    #      [HYBRID:] <better query>                (planned: semantic+bm25+RRF)
    #      [SEMANTIC_RERANK:] <better query>       (implemented: widen+keyword rerank)
    #      [DIRECT:] <optional>
    - id: call_model_router
      action: call_model
      prompt_key: "rejewski_router_v1"
      next: handle_router_prefix

    # 6) Parse router output and route execution.
    - id: handle_router_prefix
      action: handle_prefix
      semantic_prefix: "[SEMANTIC:]"
      bm25_prefix: "[BM25:]"
      hybrid_prefix: "[HYBRID:]"
      semantic_rerank_prefix: "[SEMANTIC_RERANK:]"
      direct_prefix: "[DIRECT:]"
      on_semantic: fetch_more_context
      on_bm25: fetch_more_context
      on_hybrid: fetch_more_context
      on_semantic_rerank: fetch_more_context
      on_direct: call_model_answer
      on_other: call_model_answer

    # 7) Perform retrieval according to router decision.
    #    Important: action reads the chosen mode + query from pipeline state set by handle_prefix.
    #    Modes:
    #      - semantic          => FAISS
    #      - bm25              => BM25
    #      - semantic_rerank    => FAISS(widen) then keyword rerank (your current class)
    #      - hybrid            => RRF(semantic, bm25) (future)
    - id: fetch_more_context
      action: fetch_more_context
      next: expand_dependency_tree

    # 8) Expand around retrieved entry points using RoslynIndexer graph.
    - id: expand_dependency_tree
      action: expand_dependency_tree
      repository_from_settings: true
      active_index_from_settings: true
      max_depth_from_settings: "graph_max_depth"
      max_nodes_from_settings: "graph_max_nodes"
      edge_allowlist_from_settings: "graph_edge_allowlist"
      next: fetch_node_texts

    # 9) Targeted lookup by identity for node texts/snippets.
    - id: fetch_node_texts
      action: fetch_node_texts
      top_n_from_settings: "node_text_fetch_top_n"
      next: check_context_budget

    # 10) Ensure composed context fits max_context_tokens.
    - id: check_context_budget
      action: check_context_budget
      input: composed_context_for_prompt
      max_tokens_from_settings: "max_context_tokens"
      on_over_limit: call_model_summarize_context
      on_ok: call_model_answer

    # 11) Summarize context if needed.
    - id: call_model_summarize_context
      action: call_model
      prompt_key: "rejewski_summarizer_v1"
      next: call_model_answer

    # 12) Main answer step.
    #     Output must start with:
    #       [Answer:] ...
    #       [Requesting data on:] ...
    - id: call_model_answer
      action: call_model
      prompt_key: "rejewski_answer_v1"
      next: handle_answer_prefix

    # 13) Decide: finalize or loop for more context.
    - id: handle_answer_prefix
      action: handle_prefix
      answer_prefix: "[Answer:]"
      followup_prefix: "[Requesting data on:]"
      on_answer: persist_turn_and_finalize
      on_followup: loop_guard
      on_other: finalize_heuristic

    # 14) Loop guard: stop after max_turn_loops.
    - id: loop_guard
      action: loop_guard
      max_turn_loops_from_settings: "max_turn_loops"
      on_allow: fetch_more_context
      on_deny: finalize_heuristic

    # 15) Safety net finalization if prefixes are violated / loop denied.
    - id: finalize_heuristic
      action: finalize_heuristic
      next: persist_turn_and_finalize

    # 16) Persist conversation turn (and summary state).
    - id: persist_turn_and_finalize
      action: persist_turn_and_finalize
      next: finalize

    # 17) Final user-facing response (translate back if needed).
    - id: finalize
      action: finalize
      end: true